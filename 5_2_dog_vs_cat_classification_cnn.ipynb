{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5.2 dog_vs_cat_classification_cnn.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNX6RH2++yAJR6eD9Kru9Dv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deenukhan/deep_learning/blob/main/5_2_dog_vs_cat_classification_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKMU_fsktfH-"
      },
      "source": [
        "## **Cat vs Dog Classification - Simple CNN**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSikq_jte7Hv"
      },
      "source": [
        "# Importing the Libraries\n",
        "import os\n",
        "import zipfile \n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "F5sHbcQhfPuC",
        "outputId": "da5218f5-5de3-4458-a826-ab9de80e69bb"
      },
      "source": [
        "# Let's Download the Dataset\n",
        "# You might want to learn Keras Image Generators for this problem to solve\n",
        "cat_vs_dog_url = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "tf.keras.utils.get_file('cat_vs_dog.zip', cat_vs_dog_url, cache_dir='/content/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "68608000/68606236 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/datasets/cat_vs_dog.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7zrDXJRfm0m"
      },
      "source": [
        "# Let's Extract the Files\n",
        "zipfile.ZipFile(\"/content/datasets/cat_vs_dog.zip\", 'r').extractall('/content/datasets/')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAQpy-Ljf_i8"
      },
      "source": [
        "# Let's Check the Filenames \n",
        "# main_dir = '/content/datasets/cats_and_dogs_filtered'\n",
        "\n",
        "training_cats  = os.listdir('/content/datasets/cats_and_dogs_filtered/train/cats')\n",
        "training_dogs  = os.listdir('/content/datasets/cats_and_dogs_filtered/train/dogs')\n",
        "val_cats  = os.listdir('/content/datasets/cats_and_dogs_filtered/validation/cats')\n",
        "val_dogs  = os.listdir('/content/datasets/cats_and_dogs_filtered/validation/dogs')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OwBjzY5goU9",
        "outputId": "5354152e-a738-4c60-cd6f-8199b823a769"
      },
      "source": [
        "# Printing some length and few filenames \n",
        "print(\"Training Cats Filenames : \", training_cats[:5])\n",
        "print(\"Training Dogs Filenames : \", training_dogs[:5])\n",
        "print(\"Validation Cats Filenames: \", val_cats[:5])\n",
        "print(\"Training Dogs Filenamse: \", val_dogs[:5])\n",
        "\n",
        "print(\"Total Training Dogs : \", len(training_dogs))\n",
        "print(\"Total Training Cats : \", len(training_cats))\n",
        "print(\"Total Validation Dogs : \", len(val_cats))\n",
        "print(\"Total Validation Cats : \", len(val_dogs))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Cats Filenames :  ['cat.657.jpg', 'cat.639.jpg', 'cat.776.jpg', 'cat.411.jpg', 'cat.298.jpg']\n",
            "Training Dogs Filenames :  ['dog.40.jpg', 'dog.684.jpg', 'dog.628.jpg', 'dog.320.jpg', 'dog.618.jpg']\n",
            "Validation Cats Filenames:  ['cat.2498.jpg', 'cat.2117.jpg', 'cat.2465.jpg', 'cat.2122.jpg', 'cat.2040.jpg']\n",
            "Training Dogs Filenamse:  ['dog.2467.jpg', 'dog.2190.jpg', 'dog.2453.jpg', 'dog.2129.jpg', 'dog.2002.jpg']\n",
            "Total Training Dogs :  1000\n",
            "Total Training Cats :  1000\n",
            "Total Validation Dogs :  500\n",
            "Total Validation Cats :  500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "177pOYNgix5h",
        "outputId": "3070ec1c-fe4c-4452-8fe0-01538b4ef773"
      },
      "source": [
        "# Creating the Image Generator Pipelines for Training and Validation data\n",
        "train_img_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n",
        "val_img_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "train_img_gen = train_img_gen.flow_from_directory(\n",
        "                '/content/datasets/cats_and_dogs_filtered/train',\n",
        "                target_size = (150, 150),\n",
        "                batch_size = 32,\n",
        "                shuffle = True, \n",
        "                class_mode = 'binary'\n",
        ")\n",
        "\n",
        "val_img_gen = val_img_gen.flow_from_directory(\n",
        "                '/content/datasets/cats_and_dogs_filtered/validation',\n",
        "                target_size = (150, 150),\n",
        "                batch_size = 32,\n",
        "                shuffle = True, \n",
        "                class_mode = 'binary'\n",
        ")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Q_nyMZhjPOd"
      },
      "source": [
        "# Let's Create the Convolution Model\n",
        "keras.backend.clear_session()\n",
        "\n",
        "# Model was overfitting before adding the Dropout layers\n",
        "# you can remove the Dropout Layers and See for you self\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "        keras.layers.Conv2D(filters=16, kernel_size=3, input_shape=(150, 150, 3), activation='relu'),\n",
        "        keras.layers.MaxPooling2D(2, 2),\n",
        "        keras.layers.Dropout(0.4),\n",
        "        keras.layers.Conv2D(filters=32, kernel_size=3,  activation='relu'),\n",
        "        keras.layers.MaxPooling2D(2, 2),\n",
        "        keras.layers.Dropout(0.4),\n",
        "        keras.layers.Conv2D(filters=64, kernel_size=3,  activation='relu'),\n",
        "        keras.layers.MaxPooling2D(2, 2),\n",
        "        keras.layers.Dropout(0.4),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(64, activation = 'relu'),\n",
        "        keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compiling the Model\n",
        "model.compile(optimizer = keras.optimizers.RMSprop(learning_rate=0.001), loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRYSsLGSkTru",
        "outputId": "cba8a388-56a4-4761-da02-34d760b9e671"
      },
      "source": [
        "# Training the Model\n",
        "model.fit(train_img_gen,  epochs = 10, validation_data=val_img_gen)\n",
        "\n",
        "# Here We can see the we got Roughly 73% Accuracy and our model is not overfitted"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "63/63 [==============================] - 11s 160ms/step - loss: 1.1583 - accuracy: 0.4755 - val_loss: 0.6864 - val_accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "63/63 [==============================] - 10s 156ms/step - loss: 0.6912 - accuracy: 0.5488 - val_loss: 0.6750 - val_accuracy: 0.6260\n",
            "Epoch 3/10\n",
            "63/63 [==============================] - 10s 156ms/step - loss: 0.6513 - accuracy: 0.6196 - val_loss: 0.6676 - val_accuracy: 0.5470\n",
            "Epoch 4/10\n",
            "63/63 [==============================] - 10s 154ms/step - loss: 0.6138 - accuracy: 0.6582 - val_loss: 0.6663 - val_accuracy: 0.5810\n",
            "Epoch 5/10\n",
            "63/63 [==============================] - 10s 153ms/step - loss: 0.5863 - accuracy: 0.6945 - val_loss: 0.6088 - val_accuracy: 0.6470\n",
            "Epoch 6/10\n",
            "63/63 [==============================] - 10s 155ms/step - loss: 0.5655 - accuracy: 0.6941 - val_loss: 0.5899 - val_accuracy: 0.6760\n",
            "Epoch 7/10\n",
            "63/63 [==============================] - 10s 154ms/step - loss: 0.5377 - accuracy: 0.7255 - val_loss: 0.6209 - val_accuracy: 0.6490\n",
            "Epoch 8/10\n",
            "63/63 [==============================] - 10s 154ms/step - loss: 0.5146 - accuracy: 0.7558 - val_loss: 0.5742 - val_accuracy: 0.7010\n",
            "Epoch 9/10\n",
            "63/63 [==============================] - 10s 158ms/step - loss: 0.4880 - accuracy: 0.7641 - val_loss: 0.5941 - val_accuracy: 0.6650\n",
            "Epoch 10/10\n",
            "63/63 [==============================] - 10s 157ms/step - loss: 0.4864 - accuracy: 0.7762 - val_loss: 0.5485 - val_accuracy: 0.7360\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7feae0263290>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoXiTTjXo8Yo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}